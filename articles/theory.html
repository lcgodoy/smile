<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="smile">
<title>4. Theory • smile</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><link href="../deps/_Roboto-0.4.0/font.css" rel="stylesheet">
<link href="../deps/_JetBrains%20Mono-0.4.0/font.css" rel="stylesheet">
<link href="../deps/_Roboto%20Slab-0.4.0/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="4. Theory">
<meta property="og:description" content="smile">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">smile</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-2">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown--vignettes">
    <span class="fa fa-book fa-lg"></span>
     
    Vignettes
  </a>
  <div class="dropdown-menu" aria-labelledby="dropdown--vignettes">
    <a class="dropdown-item" href="../articles/sf-to-spm.html">1. Converting sf objects to spm</a>
    <a class="dropdown-item" href="../articles/sp-cov-functions.html">2. Spatial covariance functions</a>
    <a class="dropdown-item" href="../articles/fit-and-pred.html">3. Fitting models and making predictions</a>
    <a class="dropdown-item" href="../articles/theory.html">4. Theory</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">
    <span class="fa fa-search fa-lg"></span>
     
    Reference
  </a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/lcgodoy">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://stacksoverflow.com/users/9220758/lcgodoy">
    <span class="fa fa-stack-overflow fa-lg"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://twitter.com/ldcgodoy">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://www.linkedin.com/in/godoy-lucas/">
    <span class="fa fa-linkedin"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">
<script src="theory_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main"><div class="page-header">
      <img src="" class="logo" alt=""><h1>4. Theory</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/lcgodoy/smile/blob/HEAD/vignettes/theory.Rmd" class="external-link"><code>vignettes/theory.Rmd</code></a></small>
      <div class="d-none name"><code>theory.Rmd</code></div>
    </div>

    
    
<blockquote>
<p>What I did for this package was based on the work from <span class="citation">Johnson, Diggle, and Giorgi (2020)</span>.</p>
</blockquote>
<div class="section level1">
<h1 id="theoretical-background">Theoretical Background<a class="anchor" aria-label="anchor" href="#theoretical-background"></a>
</h1>
<div class="section level2">
<h2 id="univariate-y-and-no-x">Univariate <span class="math inline">\(Y\)</span> and no <span class="math inline">\(X\)</span><a class="anchor" aria-label="anchor" href="#univariate-y-and-no-x"></a>
</h2>
<p>Let <span class="math inline">\(\{ U(\mathbf{x}) \,:\, x \in D \subset \mathbb{R}^2 \}\)</span> (being <span class="math inline">\(D\)</span> the whole region of study, tipically a city) be a stationary and isotropic Gaussian Random Field <span class="citation">(Rue and Held 2005)</span> with mean constant and equal to zero over the space and covariance function <span class="math inline">\(C(h; \mathbf{\theta})\)</span>, where <span class="math inline">\(h\)</span> is the euclidean distance between two given points within <span class="math inline">\(D\)</span>, and <span class="math inline">\(\mathbf{\theta}\)</span> is the vector of parameters controling the spatial covariance structure of such process. Now, let <span class="math inline">\(\mathbf{Y}\)</span> to be a random variable observed at a partition of <span class="math inline">\(D\)</span> defined as <span class="math inline">\(A = \{A_1, \dots, A_n \}\)</span>. Then, we define <span class="math display">\[
Y( A_i ) = \alpha + U( A_i ) + \epsilon_i, \, i = 1, ..., n,
\]</span> where <span class="math display">\[
U ( A_i ) = \frac{ 1 }{ \lvert A_i \rvert } \int_{A_i} U ( x ) \, dx,
\]</span> and <span class="math inline">\(\epsilon_i \overset{iid}{\sim} N(0, \omega)\)</span>. Also, we assume <span class="math inline">\(\epsilon \perp U\)</span>. The expected value for <span class="math inline">\(Y( A_i )\)</span> is <span class="math display">\[
E[ Y ( A_i  )  ] = \alpha,
\]</span> while its variance/covarianca matrix is given as follows <span class="math display">\[\begin{align*}
Cov[ Y ( A_i ), Y ( A_j ) ] &amp; = Cov[\alpha + U( A_i ) + \epsilon_i, \alpha + U(
A_j ) + \epsilon_j] \\
&amp; = Cov[ U( A_i ), U( A_j ) ] 
= Cov \left[ \frac{1}{\lvert A_i \rvert} \int_{A_i} U ( \mathbf{s}_1 ) \, d\mathbf{s}_1,
\frac{1}{\lvert A_j \rvert} \int_{A_j} U ( \mathbf{s}_2 ) \, d\mathbf{s}_2 \right] \\
&amp; =
\frac{1}{\lvert A_i \rvert \lvert A_j \rvert} \int_{A_j} \int_{A_i}
Cov \left[ U ( \mathbf{s}_2 ),
U ( \mathbf{s}_2 )  \right]
\, d\mathbf{s}_1 \, d\mathbf{s}_2 \\
&amp; = 
\frac{1}{\lvert A_i \rvert \lvert A_j \rvert} \int_{A_j} \int_{A_i}
C( \lVert \mathbf{s}_1 - \mathbf{s}_2 \rVert ; \theta) d\mathbf{s}_1 \, d\mathbf{s}_2 
= f(A_i, A_j ; \theta).
\end{align*}\]</span> First, note that the Covariance function is a integral. Implying that, in the manipulations above, we are simply switching the order of the integrals. This is valid as long as the integrals are well defined (not equal to infinity). Additionally, when <span class="math inline">\(i = j\)</span>, the variance at the region <span class="math inline">\(A_i\)</span> is <span class="math display">\[
Var[ Y ( A_i ) ] = Cov[ Y ( A_i ), Y ( A_i ) ] = ... = \omega + \frac{1}{\lvert
A_i \rvert^2} \int_{A_i} \int_{A_i} C( \lVert \mathbf{s}_1 - \mathbf{s}_2 \rVert
; \theta) d\mathbf{s}_1 \, d\mathbf{s}_2.
\]</span></p>
</div>
<div class="section level2">
<h2 id="multivariate-y-and-no-x">Multivariate <span class="math inline">\(Y\)</span> and no <span class="math inline">\(X\)</span><a class="anchor" aria-label="anchor" href="#multivariate-y-and-no-x"></a>
</h2>
<p>Consider the process <span class="math inline">\(\{ U(\mathbf{x}) \,:\, x \in D \subset \mathbb{R}^2 \}\)</span> having the same process as the one defined in the previous section, and a region of study <span class="math inline">\(D\)</span>. Now, let <span class="math inline">\(\mathbf{Y}\)</span> to be a <em>p</em>-dimensional random variable observed at a partition of <span class="math inline">\(D\)</span> defined as <span class="math inline">\(A = \{A_1, \dots, A_n \}\)</span>. Then, we define <span class="math display">\[
Y ( A_i )_k = \alpha_k + U( A_i ) + V_k, \, i = 1, \ldots, n, k = 1, \ldots, p,
\]</span> with <span class="math inline">\(U \perp V\)</span>, and <span class="math display">\[
V_k \overset{iid}{\sim} N\left(\mathbf{0}, \Omega \right),
\]</span> where <span class="math inline">\(\Omega\)</span> is a covariance matrix (not necessarily a diagonal matrix). Then, using similar calculations, we have <span class="math display">\[
Y \sim N( \mathbf{1}_n \otimes \mathbf{\alpha}, 
\mathbf{J}_p \otimes \Sigma_{A} + \mathbf{I}_n \otimes \Omega ),
\]</span> where <span class="math inline">\(\Sigma_{A}\)</span> is defined analogously as the variance and covariance matrix of the univariate <span class="math inline">\(Y\)</span>, <span class="math inline">\(\mathbf{1}_n\)</span> is a vector of ones, <span class="math inline">\(\mathbf{J}_p\)</span> is a matrix of ones, and <span class="math inline">\(\mathbf{I}_n\)</span> is a identity matrix.</p>
</div>
<div class="section level2">
<h2 id="p-dimensional-y-and-univariate-x">
<span class="math inline">\(p\)</span>-dimensional <span class="math inline">\(Y\)</span> and univariate <span class="math inline">\(X\)</span><a class="anchor" aria-label="anchor" href="#p-dimensional-y-and-univariate-x"></a>
</h2>
<p>Let <span class="math inline">\(\{ U(\mathbf{x}) \,:\, x \in D \subset \mathbb{R}^2 \}\)</span> (being <span class="math inline">\(D\)</span> the whole region of study) be a stationary and isotropic Gaussian Random Field with covariance function <span class="math inline">\(C(h; \mathbf{\theta})\)</span>, where <span class="math inline">\(h\)</span> is the euclidean distance between any two points within <span class="math inline">\(D\)</span>, and <span class="math inline">\(\mathbf{\theta}\)</span> is the vector of parameters controling the spatial structure of <span class="math inline">\(U(\mathbf{x})\)</span>. Now, let <span class="math inline">\(\mathbf{Y}\)</span> to be a <span class="math inline">\(p\)</span>-dimensional random variable observed at a partition of <span class="math inline">\(D\)</span> defined as <span class="math inline">\(A = \{A_1, \dots, A_n \}\)</span> and <span class="math inline">\(\mathbf{X}\)</span> to be a random variable observed at a different partition of the same space denoted by <span class="math inline">\(B = \{B_1, \dots, B_m \}\)</span>. We define each of these variables as follows <span class="math display">\[\begin{equation}
\label{eq:model_1}
\left \{
\begin{array}{l}
Y_{ij} = \alpha_j + \beta_j U( A_i ) + V_{ij}, \, i = 1, \dots, n; \, j = 1, \dots, p \\
X_{k} = \gamma + U( B_k ) + T_{k}, \, k = 1, \dots, m;
\end{array} \right.
\end{equation}\]</span> where <span class="math display">\[
\begin{array}{l}
U( A_i ) = \lvert A_i \rvert ^ {-1} \int_{A_i} U(\mathbf{s}) \, d \mathbf{s} \\
U( B_k ) = \lvert B_k \rvert ^ {-1} \int_{B_k} U(\mathbf{s}) \, d \mathbf{s} \\
V_{i} = (V_{i1}, \dots, V_{ip})' \overset{iid}{\sim} N(\mathbf{0}, \Omega) \\
T_{k} = \overset{iid}{\sim} N(0, \tau^2) \\
T_{k} \perp V_{i} , \quad T_{k} \perp U, \quad V_{i} \perp U, \; 
\forall \, i = 1, \dots, n, \, j = 1, \dots , m
\end{array}
\]</span> where <span class="math inline">\(\Omega\)</span> is a <span class="math inline">\(p \times p\)</span> matrix with entries <span class="math inline">\(\omega_{ij}\)</span>.</p>
<p>Now, we have that the covariance structure of the underlying process on the observed polygons belonging to the partition <span class="math inline">\(A\)</span> is defined as <span class="math display">\[
( \Sigma_A )_{ij} = \frac{1}{\lvert A_i \rvert \lvert A_j \rvert} \int_{A_i}
\int_{A_j} C(\Vert \mathbf{s}_1 - \mathbf{s}_1 \Vert) \, d \mathbf{s}_2 d
\mathbf{s}_2 = f(A_i, A_j ; \theta),
\]</span> while the entries of the covariance matrix for the same process over the regions belonging to <span class="math inline">\(B\)</span> are given by <span class="math display">\[
( \Sigma_B )_{kl} = \frac{1}{\lvert B_k \rvert \lvert B_l \rvert} \int_{B_k}
\int_{B_l} C(\Vert \mathbf{s}_1 - \mathbf{s}_1 \Vert) \, d \mathbf{s}_2 d
\mathbf{s}_2 = f(B_k, B_l ; \theta),
\]</span> with <span class="math inline">\(f( \cdot ; \theta)\)</span> defined similarly.</p>
<p>The covariance between <span class="math inline">\(Y_{ij}\)</span> and <span class="math inline">\(Y_{i'j'}\)</span> is <span class="math display">\[
Cov(Y_{ij}, Y_{i'j'}) = \beta_j \beta_{j'} f(A_i, A_{i'} ; \theta),
\]</span> Therefore, the covariance matrix associated with the random variable <span class="math inline">\(\mathbf{Y}\)</span> is <span class="math display">\[
\Sigma_Y = \mathbf{\beta} \mathbf{\beta}^{\top} \otimes \Sigma_A +
\Omega \otimes \mathbf{I}_n \, \in \, 
\mathbb{R}^{(p \cdot n) \times (p \cdot n)},
\]</span> and <span class="math display">\[
\Sigma_X = \Sigma_B + \tau^2 \cdot \mathbf{I}_n \, \in \, 
\mathbb{R}^{(p \cdot n) \times (p \cdot n)}.
\]</span></p>
<p>Moreover, the following “cross” covariance relationship between <span class="math inline">\(Y_{j}\)</span> and <span class="math inline">\(X\)</span> has entries <span class="math display">\[
(D_j)_{ik} = Cov(Y_{ij}, X_{k}) = \beta_j f(A_i, B_k ; \theta),
\]</span> where <span class="math inline">\(D_j\)</span> is <span class="math inline">\(n \times m\)</span>. Thus, we define the “cross”-covariance as <span class="math display">\[
D = \begin{pmatrix}
D_1 &amp; \cdots &amp; D_p
\end{pmatrix}^{\top} \, \in \, \mathbb{R}^{ (p \cdot n) \times m}
\]</span></p>
<p>We can write the joint log-likelihood as <span class="math display">\[
l_{\mathbf{Y}\mathbf{X}}(\theta) = 
l_{\mathbf{Y}|\mathbf{X}}(\theta) +
l_{\mathbf{X}}(\theta),
\]</span> being here <span class="math inline">\(\theta\)</span> the vector of unknown parameters. With <span class="math display">\[
(\mathbf{Y} | \mathbf{X} = \mathbf{x}) \sim N(\mu_{Y|X}, \Sigma_{Y|X}),
\]</span> where <span class="math display">\[\begin{align*}
&amp; \mu_{Y|X} = \mathbf{1}_n \otimes \mathbf{\alpha} + 
D \Sigma^{-1}_X ( \mathbf{x} - \gamma \cdot \mathbf{1}_m)  \, \in \, 
\mathbb{R}^{p \cdot } \\
&amp; \Sigma_{Y|X} = \Sigma_Y - D \Sigma^{-1}_X D^{\top}  \, \in \, 
\mathbb{R}^{(p \cdot n) \times (p \cdot n)},
\end{align*}\]</span> come from standard theoremos involving the multivariate normal <span class="citation">(Ravishanker and Dey 2020)</span>.</p>
</div>
</div>
<div class="section level1">
<h1 id="limitations-and-further-work">Limitations and Further Work<a class="anchor" aria-label="anchor" href="#limitations-and-further-work"></a>
</h1>
<p>It is known from the literature of geostatistics, that the small scale variance parameters are hard to be estimated due to identifiability problems, unless the researcher knows, for example, the ratio of the variance and this effect. This parameters, for the considered models, are <span class="math inline">\(\omega\)</span>, <span class="math inline">\(\tau^2\)</span>, and <span class="math inline">\(\Omega\)</span>. This last one is not properly a nugget effect, since it can also includes terms of covariance between variables.</p>
<p>Different methods of estimation need to be implemented and the problem needs to be further examined.</p>
</div>
<div class="section level1 unnumbered">
<h1 id="reference">Reference<a class="anchor" aria-label="anchor" href="#reference"></a>
</h1>
<div id="refs" class="references">
<div id="ref-johnson2020dealing">
<p>Johnson, Olatunji, Peter Diggle, and Emanuele Giorgi. 2020. “Dealing with Spatial Misalignment to Model the Relationship Between Deprivation and Life Expectancy: A Model-Based Geostatistical Approach.” <em>International Journal of Health Geographics</em> 19 (1): 1–13.</p>
</div>
<div id="ref-ravishanker2020first">
<p>Ravishanker, Nalini, and Dipak K Dey. 2020. “A First Course in Linear Model Theory.” In, 156. CRC Press.</p>
</div>
<div id="ref-rue2005gaussian">
<p>Rue, Havard, and Leonhard Held. 2005. <em>Gaussian Markov Random Fields: Theory and Applications</em>. Chapman; Hall/CRC.</p>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>NULL</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>NULL Provided without <strong>any warranty</strong>.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
